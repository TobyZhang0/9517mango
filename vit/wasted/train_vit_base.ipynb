{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# import libraries",
   "id": "a5857661c2c0dbd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import timm\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from torch import nn, optim\n",
    "import os\n",
    "import sys\n",
    "from dataset import create_dataloaders  # 从dataset.py导入create_dataloaders函数\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"PyTorch版本: {torch.__version__}\")\n",
    "print(f\"CUDA是否可用: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"当前GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n"
   ],
   "id": "3141668c6f242815",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# parameters",
   "id": "2247f4cc93aa3ad4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "# 设置数据路径\n",
    "data_root = os.path.abspath(os.path.join(\"..\",\"Aerial_Landscapes\"))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 可以尝试不同的增强策略进行训练\n",
    "strategies = ['default', 'minimal', 'extensive', 'new']\n",
    "num_classes = 15\n",
    "# 设置训练参数\n",
    "batch_size = 64\n",
    "num_epochs = 5\n",
    "learning_rate = 0.0001\n",
    "class_weights = torch.ones(15)\n",
    "\n",
    "# 增加容易混淆类别的权重\n",
    "class_weights[0] = 1.2\n",
    "class_weights[6] = 1.2\n",
    "class_weights[3] = 1.2\n",
    "class_weights[13] = 1.2\n",
    "class_weights[11] = 1.5\n",
    "class_weights[8] = 1.5\n",
    "class_weights[14] = 1.2\n",
    "class_weights = class_weights.to(device)"
   ],
   "id": "92c28116a68e5ee0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_model(num_classes=15, mode='train',print_structure=False):\n",
    "    if mode == 'train':\n",
    "        # 使用更大的模型版本\n",
    "        model = timm.create_model('vit_base_patch16_224', pretrained=True, drop_rate=0.15, attn_drop_rate=0.1)\n",
    "\n",
    "        # 添加更复杂的分类头\n",
    "        in_features = model.head.in_features\n",
    "        model.head = nn.Sequential(\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    else:\n",
    "        model = timm.create_model('vit_base_patch16_224', pretrained=False)\n",
    "        in_features = model.head.in_features\n",
    "        model.head = nn.Sequential(\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    if print_structure:\n",
    "        print(model)\n",
    "    return model\n",
    "# 可视化混淆矩阵\n",
    "def plot_confusion_matrix(conf_matrix, classes):\n",
    "    print(\"绘制混淆矩阵...\")\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.show()\n",
    "    print(f\"混淆矩阵已保存为 'confusion_matrix.png'\")\n",
    "\n"
   ],
   "id": "4c519703d6dea7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # 使用dataset.py创建数据加载器\n",
    "# print(\"\\n正在加载数据...\")\n",
    "# try:\n",
    "#     # 使用导入的create_dataloaders函数，指定增强策略为\"default\"\n",
    "#     train_loader, val_loader, test_loader, classes = create_dataloaders(\n",
    "#         root_dir=data_root,\n",
    "#         batch_size=batch_size,\n",
    "#         split_ratio=[0.6, 0.2, 0.2],\n",
    "#         augmentation_strategy='minimal',\n",
    "#         random_seed=42,\n",
    "#         num_workers=0,\n",
    "#         verbose=True\n",
    "#     )\n",
    "#     print(f\"数据加载完成。类别数: {len(classes)}, 类别: {classes}\")\n",
    "# except Exception as e:\n",
    "#     print(f\"加载数据时出错: {e}\")\n"
   ],
   "id": "113a595c5e93b9de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 定义损失函数和优化器\n",
    "# 使用基于混淆矩阵的类权重\n",
    "\n",
    "global_best_acc = 0.0\n",
    "global_best_state = None\n",
    "global_best_strategy = None\n",
    "\n",
    "for st in strategies:\n",
    "    print(f\"\\n=== Training with {st} ===\")\n",
    "    train_loader, val_loader, _, class_names = create_dataloaders(\n",
    "        root_dir=data_root, batch_size=batch_size, augmentation_strategy=st, verbose=False\n",
    "    )\n",
    "\n",
    "    model = create_model(num_classes)\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_state = None\n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        correct = total = 0\n",
    "\n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        train_acc = correct / total\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        val_acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}/10 | Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        scheduler.step(train_loss)\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_state = model.state_dict()\n",
    "\n",
    "    if best_val_acc > global_best_acc:\n",
    "        global_best_acc = best_val_acc\n",
    "        global_best_state = best_state\n",
    "        global_best_strategy = st\n",
    "\n",
    "    # 绘制训练曲线\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history['train_loss'], label='Training Loss')\n",
    "    plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Metrics')\n",
    "    plt.title(f'Training Curve ({st})')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# 保存全局最佳模型\n",
    "os.makedirs(\"saved_models_vit\", exist_ok=True)\n",
    "torch.save(global_best_state, f\"saved_models_vit/best_vit_{global_best_strategy}.pth\")\n",
    "print(f\"Global best: {global_best_strategy} @ {global_best_acc:.4f}\")\n",
    "#\n",
    "# for st in strategies:\n",
    "#     criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n",
    "#\n",
    "#     optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "#     scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "#\n",
    "#     # 训练模型\n",
    "#     model = create_model(num_classes)\n",
    "#     model = model.to(device)\n",
    "#     history = {\n",
    "#         'train_loss': [],\n",
    "#         'val_loss': [],\n",
    "#         'train_acc': [],\n",
    "#         'val_acc': [],\n",
    "#         'epoch_time': [],\n",
    "#         'batch_losses': []  # 保留这个记录，用于训练后的可视化\n",
    "#     }\n",
    "#\n",
    "#     best_val_acc = 0.0\n",
    "#     batch_losses = []\n",
    "#     total_batch = 0\n",
    "#\n",
    "#     for epoch in range(num_epochs):\n",
    "#         # 训练阶段\n",
    "#         model.train()\n",
    "#         train_loss = 0.0\n",
    "#         correct = 0\n",
    "#         total = 0\n",
    "#\n",
    "#         start_time = time.time()\n",
    "#         for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#\n",
    "#             train_loss += loss.item() * inputs.size(0)\n",
    "#             _, predicted = torch.max(outputs, 1)\n",
    "#             total += labels.size(0)\n",
    "#             correct += (predicted == labels).sum().item()\n",
    "#\n",
    "#             # 记录当前batch的损失\n",
    "#             batch_losses.append(loss.item())\n",
    "#             total_batch += 1\n",
    "#\n",
    "#             # 显示简单的进度条\n",
    "#             if (batch_idx + 1) % 10 == 0 or batch_idx == len(train_loader) - 1:\n",
    "#                 batch_acc = (predicted == labels).sum().item() / labels.size(0)\n",
    "#                 print(f\"Batch进度: {batch_idx + 1}/{len(train_loader)}, Loss: {loss.item():.4f}, 准确率: {batch_acc:.4f}\",\n",
    "#                       end='\\r')\n",
    "#\n",
    "#         train_loss = train_loss / len(train_loader.dataset)\n",
    "#         train_acc = correct / total\n",
    "#\n",
    "#         # 保存每个epoch结束时的所有batch损失\n",
    "#         history['batch_losses'].extend(batch_losses[-len(train_loader):])\n",
    "#\n",
    "#         # 验证阶段\n",
    "#         model.eval()\n",
    "#         val_loss = 0.0\n",
    "#         correct = 0\n",
    "#         total = 0\n",
    "#\n",
    "#         with torch.no_grad():\n",
    "#             for inputs, labels in val_loader:\n",
    "#                 inputs, labels = inputs.to(device), labels.to(device)\n",
    "#                 outputs = model(inputs)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "#\n",
    "#                 val_loss += loss.item() * inputs.size(0)\n",
    "#                 _, predicted = torch.max(outputs, 1)\n",
    "#                 total += labels.size(0)\n",
    "#                 correct += (predicted == labels).sum().item()\n",
    "#\n",
    "#         val_loss = val_loss / len(val_loader.dataset)\n",
    "#         val_acc = correct / total\n",
    "#\n",
    "#         # 学习率调整\n",
    "#         current_lr = optimizer.param_groups[0]['lr']\n",
    "#         scheduler.step(val_loss)\n",
    "#         new_lr = optimizer.param_groups[0]['lr']\n",
    "#\n",
    "#         # 计算epoch时间\n",
    "#         epoch_time = time.time() - start_time\n",
    "#\n",
    "#         # 保存最佳模型\n",
    "#         is_best = val_acc > best_val_acc\n",
    "#         if is_best:\n",
    "#             best_val_acc = val_acc\n",
    "#             torch.save(model.state_dict(), 'best_vit_model.pth')\n",
    "#             best_mark = \"✓ [最佳]\"\n",
    "#         else:\n",
    "#             best_mark = \"\"\n",
    "#\n",
    "#         # 记录历史\n",
    "#         history['train_loss'].append(train_loss)\n",
    "#         history['val_loss'].append(val_loss)\n",
    "#         history['train_acc'].append(train_acc)\n",
    "#         history['val_acc'].append(val_acc)\n",
    "#         history['epoch_time'].append(epoch_time)\n",
    "#\n",
    "#         # 美化打印输出\n",
    "#         print(f\"\\n{'-' * 80}\")\n",
    "#         print(f\"Epoch {epoch + 1}/{num_epochs} 完成 - 耗时: {epoch_time:.2f}秒 {best_mark}\")\n",
    "#         print(f\"学习率: {current_lr:.8f} {'→ ' + str(new_lr) if current_lr != new_lr else ''}\")\n",
    "#         print(f\"训练集 - Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f} ({correct}/{total})\")\n",
    "#         print(f\"验证集 - Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\")\n",
    "#         if is_best:\n",
    "#             print(f\"✓ 新的最佳模型已保存! (验证准确率: {val_acc:.4f})\")\n",
    "#         print(f\"{'-' * 80}\")\n",
    "#\n",
    "#     print(f\"\\n{'-' * 80}\")\n",
    "#     print(f\"训练完成! 最佳验证准确率: {best_val_acc:.4f}\")\n",
    "#     print(f\"{'-' * 80}\")\n",
    "#\n",
    "\n"
   ],
   "id": "5852af24857c428f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 可视化训练历史",
   "id": "94824346397d4c38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"绘制训练历史图表...\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# 绘制损失曲线\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(history['train_loss'], label='Training Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Curves')\n",
    "plt.legend()\n",
    "\n",
    "# 绘制准确率曲线\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(history['train_acc'], label='Training Accuracy')\n",
    "plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy Curves')\n",
    "plt.legend()\n",
    "\n",
    "# 绘制每个batch的损失曲线\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(range(len(history['batch_losses'])), history['batch_losses'])\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss per Batch')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png')\n",
    "plt.show()\n",
    "\n",
    "print(f\"图表已保存为 'training_history.png'\")\n"
   ],
   "id": "3164ab8072088130",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 加载最佳模型\n",
    "\n",
    "best_model = create_model(num_classes=num_classes, mode='test')\n",
    "best_model.load_state_dict(torch.load('best_vit_model.pth'))\n",
    "print(\"最佳模型加载完成\")\n",
    "\n",
    "_, _, test_loader, classes = create_dataloaders(\n",
    "    root_dir=data_root,\n",
    "    batch_size=batch_size,\n",
    "    augmentation_strategy='minimal',\n",
    "    split_ratio=[0.6, 0.2, 0.2],\n",
    "    random_seed=42,\n",
    "    num_workers=0,\n",
    "    verbose=False\n",
    ")\n",
    "def test_model(model, test_loader, classes):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    # 添加进度显示\n",
    "    total_batches = len(test_loader)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "            print(f\"测试进度: {batch_idx + 1}/{total_batches} 批次\", end='\\r')\n",
    "\n",
    "    # 计算混淆矩阵\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # 计算分类报告\n",
    "    report = classification_report(y_true, y_pred, target_names=classes)\n",
    "\n",
    "    # 计算总体准确率\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\n测试完成! 总体准确率: {accuracy:.4f}\")\n",
    "\n",
    "    return conf_matrix, report, accuracy, y_true, y_pred\n",
    "\n",
    "# 执行测试\n",
    "print(\"\\n正在测试模型...\")\n",
    "conf_matrix, report, accuracy, y_true, y_pred = test_model(best_model, test_loader, classes)\n",
    "# 打印测试结果\n",
    "print(f\"\\n测试准确率: {accuracy:.4f}\")\n",
    "print(\"\\n分类报告:\")\n",
    "print(report)\n",
    "print(\"\\n混淆矩阵:\")\n",
    "print(conf_matrix)\n",
    "\n"
   ],
   "id": "d677d334b6519e83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 可视化混淆矩阵\n",
    "plot_confusion_matrix(conf_matrix, classes)"
   ],
   "id": "e31ace456a703771",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 打印所有错误的预测\n",
   "id": "4502379c0d981fa8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 可视化错误预测的图像\n",
    "def visualize_misclassifications(model, test_loader, classes, y_true, y_pred, max_images=100):\n",
    "    \"\"\"\n",
    "    可视化测试集中被错误分类的图像\n",
    "\n",
    "    Args:\n",
    "        model: 训练好的模型\n",
    "        test_loader: 测试数据加载器\n",
    "        classes: 类别名称列表\n",
    "        y_true: 真实标签列表\n",
    "        y_pred: 预测标签列表\n",
    "        max_images: 最多显示的错误图像数量\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # 找出所有错误预测的索引\n",
    "    misclassified_indices = [i for i, (y_t, y_p) in enumerate(zip(y_true, y_pred)) if y_t != y_p]\n",
    "    print(f\"共有 {len(misclassified_indices)} 个错误预测\")\n",
    "\n",
    "    if len(misclassified_indices) == 0:\n",
    "        print(\"没有错误预测！模型表现完美\")\n",
    "        return\n",
    "\n",
    "    # 限制显示的图像数量\n",
    "    if len(misclassified_indices) > max_images:\n",
    "        print(f\"仅显示前 {max_images} 个错误预测\")\n",
    "        misclassified_indices = misclassified_indices[:max_images]\n",
    "\n",
    "    # 创建一个字典，将测试加载器的批次索引映射到真实图像和标签\n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "\n",
    "    print(\"收集测试数据...\")\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            # 将批次中的每个图像添加到列表中\n",
    "            for i in range(inputs.size(0)):\n",
    "                all_images.append(inputs[i].cpu())\n",
    "                all_labels.append(labels[i].item())\n",
    "\n",
    "    # 检查索引是否超出范围\n",
    "    valid_indices = [i for i in misclassified_indices if i < len(all_images)]\n",
    "    if len(valid_indices) < len(misclassified_indices):\n",
    "        print(f\"警告：有 {len(misclassified_indices) - len(valid_indices)} 个索引超出范围\")\n",
    "\n",
    "    # 计算需要的行数和列数\n",
    "    n_cols = 5\n",
    "    n_rows = (len(valid_indices) + n_cols - 1) // n_cols\n",
    "\n",
    "    plt.figure(figsize=(20, 4 * n_rows))\n",
    "\n",
    "    for i, idx in enumerate(valid_indices):\n",
    "        # 获取图像和标签\n",
    "        img = all_images[idx]\n",
    "        true_label = y_true[idx]\n",
    "        pred_label = y_pred[idx]\n",
    "\n",
    "        # 转换图像格式用于显示\n",
    "        img = img.numpy().transpose((1, 2, 0))\n",
    "        # 反标准化\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        img = std * img + mean\n",
    "        img = np.clip(img, 0, 1)\n",
    "\n",
    "        # 绘制图像\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"真实: {classes[true_label]}\\n预测: {classes[pred_label]}\", color='red')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('misclassified_images.png')\n",
    "    plt.show()\n",
    "    print(f\"错误预测图像已保存为 'misclassified_images.png'\")\n",
    "\n",
    "# 调用函数，显示错误预测的图像\n",
    "print(\"\\n可视化错误预测...\")\n",
    "visualize_misclassifications(best_model, test_loader, classes, y_true, y_pred)\n"
   ],
   "id": "8d7f95d471f23ce1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Grad-CAM可视化模型决策\n",
   "id": "5c976950a1620bd6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pytorch_grad_cam import GradCAM, XGradCAM, GradCAMPlusPlus, AblationCAM, EigenCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from pytorch_grad_cam.utils.reshape_transforms import vit_reshape_transform\n",
    "def visualize_gradcam_samples(model, test_loader, classes, y_true, y_pred, num_images=5):\n",
    "    \"\"\"\n",
    "    使用GradCAM可视化模型在正确和错误预测样本上的关注区域\n",
    "\n",
    "    Args:\n",
    "        model: 训练好的模型\n",
    "        test_loader: 测试数据加载器\n",
    "        classes: 类别名称列表\n",
    "        y_true: 真实标签列表\n",
    "        y_pred: 预测标签列表\n",
    "        num_images: 每类(正确/错误)要显示的图像数量\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # 找出错误和正确预测的索引\n",
    "    misclassified_indices = [i for i, (y_t, y_p) in enumerate(zip(y_true, y_pred)) if y_t != y_p]\n",
    "    correctly_classified_indices = [i for i, (y_t, y_p) in enumerate(zip(y_true, y_pred)) if y_t == y_p]\n",
    "\n",
    "    print(f\"找到 {len(misclassified_indices)} 个错误预测和 {len(correctly_classified_indices)} 个正确预测\")\n",
    "\n",
    "    # 随机选择指定数量的样本\n",
    "    if len(misclassified_indices) > num_images:\n",
    "        misclassified_indices = np.random.choice(misclassified_indices, num_images, replace=False)\n",
    "\n",
    "    if len(correctly_classified_indices) > num_images:\n",
    "        correctly_classified_indices = np.random.choice(correctly_classified_indices, num_images, replace=False)\n",
    "\n",
    "    # 创建GradCAM对象\n",
    "    # 对于ViT模型，通常使用最后一个transformer块中的层\n",
    "    target_layers = [model.blocks[-1].norm1]  # 最后一个transformer块的第一个归一化层\n",
    "\n",
    "    # 初始化GradCAM - 移除了use_cuda参数\n",
    "    cam = GradCAM(\n",
    "        model=model,\n",
    "        target_layers=target_layers,\n",
    "        reshape_transform=vit_reshape_transform\n",
    "    )\n",
    "\n",
    "    # 收集所有图像和标签\n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "\n",
    "    print(\"收集测试数据...\")\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            # 添加每个批次的图像\n",
    "            for i in range(inputs.size(0)):\n",
    "                all_images.append(inputs[i].cpu())\n",
    "                all_labels.append(labels[i].item())\n",
    "\n",
    "    # 设置图像行数和列数\n",
    "    n_rows = 2  # 错误预测和正确预测\n",
    "    n_cols = min(num_images, len(misclassified_indices), len(correctly_classified_indices))\n",
    "    \n",
    "    # 每个示例需要2列：原图和热力图\n",
    "    plt.figure(figsize=(n_cols * 6, n_rows * 4))\n",
    "\n",
    "    # 可视化错误预测\n",
    "    print(\"生成错误预测的GradCAM...\")\n",
    "    for i, idx in enumerate(misclassified_indices[:n_cols]):\n",
    "        # 获取图像和标签\n",
    "        img_tensor = all_images[idx].unsqueeze(0).to(device)\n",
    "        true_label = y_true[idx]\n",
    "        pred_label = y_pred[idx]\n",
    "\n",
    "        # 应用GradCAM\n",
    "        targets = [ClassifierOutputTarget(pred_label)]  # 使用预测的类别\n",
    "        grayscale_cam = cam(input_tensor=img_tensor, targets=targets)\n",
    "        grayscale_cam = grayscale_cam[0, :]\n",
    "\n",
    "        # 转换图像用于显示\n",
    "        img = img_tensor.cpu().numpy().squeeze().transpose((1, 2, 0))\n",
    "        # 反标准化\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        img = std * img + mean\n",
    "        img = np.clip(img, 0, 1)\n",
    "\n",
    "        # 将GradCAM叠加到图像上\n",
    "        visualization = show_cam_on_image(img, grayscale_cam, use_rgb=True)\n",
    "\n",
    "        # 子图索引计算\n",
    "        orig_idx = i * 2 + 1\n",
    "        cam_idx = i * 2 + 2\n",
    "        \n",
    "        # 显示原始图像\n",
    "        plt.subplot(n_rows, n_cols * 2, orig_idx)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"错误预测 - 原图\\n真实: {classes[true_label]}\\n预测: {classes[pred_label]}\", color='red', fontsize=9)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # 显示GradCAM热力图\n",
    "        plt.subplot(n_rows, n_cols * 2, cam_idx)\n",
    "        plt.imshow(visualization)\n",
    "        plt.title(f\"错误预测 - 热力图\\n真实: {classes[true_label]}\\n预测: {classes[pred_label]}\", color='red', fontsize=9)\n",
    "        plt.axis('off')\n",
    "\n",
    "    # 可视化正确预测\n",
    "    print(\"生成正确预测的GradCAM...\")\n",
    "    for i, idx in enumerate(correctly_classified_indices[:n_cols]):\n",
    "        # 获取图像和标签\n",
    "        img_tensor = all_images[idx].unsqueeze(0).to(device)\n",
    "        true_label = y_true[idx]\n",
    "\n",
    "        # 应用GradCAM\n",
    "        targets = [ClassifierOutputTarget(true_label)]  # 使用真实的类别\n",
    "        grayscale_cam = cam(input_tensor=img_tensor, targets=targets)\n",
    "        grayscale_cam = grayscale_cam[0, :]\n",
    "\n",
    "        # 转换图像用于显示\n",
    "        img = img_tensor.cpu().numpy().squeeze().transpose((1, 2, 0))\n",
    "        # 反标准化\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        img = std * img + mean\n",
    "        img = np.clip(img, 0, 1)\n",
    "\n",
    "        # 将GradCAM叠加到图像上\n",
    "        visualization = show_cam_on_image(img, grayscale_cam, use_rgb=True)\n",
    "\n",
    "        # 子图索引计算\n",
    "        row_offset = n_cols * 2  # 第二行的偏移量\n",
    "        orig_idx = row_offset + i * 2 + 1\n",
    "        cam_idx = row_offset + i * 2 + 2\n",
    "        \n",
    "        # 显示原始图像\n",
    "        plt.subplot(n_rows, n_cols * 2, orig_idx)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"正确预测 - 原图\\n类别: {classes[true_label]}\", color='green', fontsize=9)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # 显示GradCAM热力图\n",
    "        plt.subplot(n_rows, n_cols * 2, cam_idx)\n",
    "        plt.imshow(visualization)\n",
    "        plt.title(f\"正确预测 - 热力图\\n类别: {classes[true_label]}\", color='green', fontsize=9)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('gradcam_visualization.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"GradCAM可视化已保存为 'gradcam_visualization.png'\")\n",
    "\n",
    "# 调用函数\n",
    "print(\"\\n使用GradCAM可视化模型决策...\")\n",
    "visualize_gradcam_samples(best_model, test_loader, classes, y_true, y_pred, num_images=5)\n"
   ],
   "id": "80246d342ec1f140",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
