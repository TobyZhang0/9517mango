{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5857661c2c0dbd",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "3141668c6f242815",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import timm\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from torch import nn, optim\n",
    "import os\n",
    "import sys\n",
    "from dataset import create_dataloaders  # Import create_dataloaders function from dataset.py\n",
    "\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current GPU: {torch.cuda.get_device_name(0)}\")\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "# Set data path\n",
    "data_root = os.path.abspath(os.path.join(\"..\",\"Aerial_Landscapes\"))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Try different augmentation strategies for training\n",
    "strategies = ['new', 'minimal', 'extensive', 'default']\n",
    "num_classes = 15\n",
    "# Set training parameters\n",
    "batch_size = 64\n",
    "num_epochs = 5\n",
    "learning_rate = 0.0001\n",
    "class_weights = torch.ones(15)\n",
    "\n",
    "# Increase weights for easily confused classes\n",
    "class_weights[0] = 1.2\n",
    "class_weights[6] = 1.2\n",
    "class_weights[3] = 1.2\n",
    "class_weights[13] = 1.2\n",
    "class_weights[11] = 1.5\n",
    "class_weights[8] = 1.5\n",
    "class_weights[14] = 1.2\n",
    "class_weights = class_weights.to(device)\n",
    "\n",
    "def create_model(num_classes=15, mode='train',print_structure=False):\n",
    "    if mode == 'train':\n",
    "        # Use larger model version\n",
    "        model = timm.create_model('vit_base_patch16_224', pretrained=True, drop_rate=0.15, attn_drop_rate=0.1)\n",
    "\n",
    "        # Add more complex classification head\n",
    "        in_features = model.head.in_features\n",
    "        model.head = nn.Sequential(\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    else:\n",
    "        model = timm.create_model('vit_base_patch16_224', pretrained=False)\n",
    "        in_features = model.head.in_features\n",
    "        model.head = nn.Sequential(\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    if print_structure:\n",
    "        print(model)\n",
    "    return model\n",
    "# Visualize confusion matrix\n",
    "def plot_confusion_matrix(conf_matrix, classes):\n",
    "    print(\"Drawing confusion matrix...\")\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Confusion matrix saved as 'confusion_matrix.png'\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5852af24857c428f",
   "metadata": {},
   "source": [
    "\n",
    "global_best_acc = 0.0\n",
    "global_best_state = None\n",
    "global_best_strategy = None\n",
    "\n",
    "for st in strategies:\n",
    "    print(f\"\\n=== Training with {st} ===\")\n",
    "    train_loader, val_loader, _, class_names = create_dataloaders(\n",
    "        root_dir=data_root, batch_size=batch_size, augmentation_strategy=st, verbose=False\n",
    "    )\n",
    "\n",
    "    model = create_model(num_classes)\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_state = None\n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': [],'batch_losses':[]}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        correct = total = 0\n",
    "\n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            history['batch_losses'].append(loss.detach().cpu().numpy())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        train_acc = correct / total\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_acc = correct / total\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        scheduler.step(train_loss)\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_state = model.state_dict()\n",
    "\n",
    "    if best_val_acc > global_best_acc:\n",
    "        global_best_acc = best_val_acc\n",
    "        global_best_state = best_state\n",
    "        global_best_strategy = st\n",
    "\n",
    "    # Draw a training curve\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.plot(history['train_loss'], label='Training Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss Curves'); plt.legend()\n",
    "\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.plot(history['train_acc'], label='Training Accuracy')\n",
    "    plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy Curves'); plt.legend()\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(range(len(history['batch_losses'])), history['batch_losses'])\n",
    "    plt.xlabel('Batch'); plt.ylabel('Loss'); plt.title('Loss per Batch'); plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    del model,history,criterion,optimizer,scheduler,train_loader,val_loader,_\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Save global best model\n",
    "os.makedirs(\"saved_models_vit\", exist_ok=True)\n",
    "torch.save(global_best_state, f\"saved_models_vit/best_vit_{global_best_strategy}.pth\")\n",
    "print(f\"Global best: {global_best_strategy} @ {global_best_acc:.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "94824346397d4c38",
   "metadata": {},
   "source": [
    "# Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "id": "3164ab8072088130",
   "metadata": {},
   "source": [
    "print(\"Drawing training history charts...\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Draw loss curves\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(history['train_loss'], label='Training Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Curves')\n",
    "plt.legend()\n",
    "\n",
    "# Draw accuracy curves\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(history['train_acc'], label='Training Accuracy')\n",
    "plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy Curves')\n",
    "plt.legend()\n",
    "\n",
    "# Draw loss curve per batch\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(range(len(history['batch_losses'])), history['batch_losses'])\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss per Batch')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Charts saved as 'training_history.png'\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d677d334b6519e83",
   "metadata": {},
   "source": [
    "# Load best model\n",
    "\n",
    "best_model = create_model(num_classes=num_classes, mode='test')\n",
    "best_model.load_state_dict(torch.load('best_vit_model.pth'))\n",
    "print(\"Best model loaded successfully\")\n",
    "\n",
    "_, _, test_loader, classes = create_dataloaders(\n",
    "    root_dir=data_root,\n",
    "    batch_size=batch_size,\n",
    "    augmentation_strategy='minimal',\n",
    "    split_ratio=[0.6, 0.2, 0.2],\n",
    "    random_seed=42,\n",
    "    num_workers=0,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "def test_model(model, test_loader, classes):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    # Add progress display\n",
    "    total_batches = len(test_loader)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "            print(f\"Test progress: {batch_idx + 1}/{total_batches} batches\", end='\\r')\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Calculate classification report\n",
    "    report = classification_report(y_true, y_pred, target_names=classes)\n",
    "\n",
    "    # Calculate overall accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\nTest completed! Overall accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    return conf_matrix, report, accuracy, y_true, y_pred\n",
    "\n",
    "# Execute test\n",
    "print(\"\\nTesting model...\")\n",
    "conf_matrix, report, accuracy, y_true, y_pred = test_model(best_model, test_loader, classes)\n",
    "# Print test results\n",
    "print(f\"\\nTest accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification report:\")\n",
    "print(report)\n",
    "print(\"\\nConfusion matrix:\")\n",
    "print(conf_matrix)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e31ace456a703771",
   "metadata": {},
   "source": [
    "# Visualize confusion matrix\n",
    "plot_confusion_matrix(conf_matrix, classes)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4502379c0d981fa8",
   "metadata": {},
   "source": [
    "# Print All Misclassified Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "8d7f95d471f23ce1",
   "metadata": {},
   "source": [
    "# Visualize misclassified images\n",
    "def visualize_misclassifications(model, test_loader, classes, y_true, y_pred, max_images=100):\n",
    "    \"\"\"\n",
    "    Visualize misclassified images in the test set\n",
    "\n",
    "    Args:\n",
    "        model: Trained model\n",
    "        test_loader: Test data loader\n",
    "        classes: List of class names\n",
    "        y_true: List of true labels\n",
    "        y_pred: List of predicted labels\n",
    "        max_images: Maximum number of misclassified images to display\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Find indices of all misclassified predictions\n",
    "    misclassified_indices = [i for i, (y_t, y_p) in enumerate(zip(y_true, y_pred)) if y_t != y_p]\n",
    "    print(f\"Found {len(misclassified_indices)} misclassified predictions\")\n",
    "\n",
    "    if len(misclassified_indices) == 0:\n",
    "        print(\"No misclassifications! Model performed perfectly\")\n",
    "        return\n",
    "\n",
    "    # Limit number of images to display\n",
    "    if len(misclassified_indices) > max_images:\n",
    "        print(f\"Only showing first {max_images} misclassified predictions\")\n",
    "        misclassified_indices = misclassified_indices[:max_images]\n",
    "\n",
    "    # Create a dictionary mapping test loader batch indices to actual images and labels\n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "\n",
    "    print(\"Collecting test data...\")\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            # Add each image in the batch to the list\n",
    "            for i in range(inputs.size(0)):\n",
    "                all_images.append(inputs[i].cpu())\n",
    "                all_labels.append(labels[i].item())\n",
    "\n",
    "    # Check if indices are out of range\n",
    "    valid_indices = [i for i in misclassified_indices if i < len(all_images)]\n",
    "    if len(valid_indices) < len(misclassified_indices):\n",
    "        print(f\"Warning: {len(misclassified_indices) - len(valid_indices)} indices out of range\")\n",
    "\n",
    "    # Calculate required rows and columns\n",
    "    n_cols = 5\n",
    "    n_rows = (len(valid_indices) + n_cols - 1) // n_cols\n",
    "\n",
    "    plt.figure(figsize=(20, 4 * n_rows))\n",
    "\n",
    "    for i, idx in enumerate(valid_indices):\n",
    "        # Get image and labels\n",
    "        img = all_images[idx]\n",
    "        true_label = y_true[idx]\n",
    "        pred_label = y_pred[idx]\n",
    "\n",
    "        # Convert image format for display\n",
    "        img = img.numpy().transpose((1, 2, 0))\n",
    "        # Denormalize\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        img = std * img + mean\n",
    "        img = np.clip(img, 0, 1)\n",
    "\n",
    "        # Draw image\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"True: {classes[true_label]}\\nPred: {classes[pred_label]}\", color='red')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('misclassified_images.png')\n",
    "    plt.show()\n",
    "    print(f\"Misclassified images saved as 'misclassified_images.png'\")\n",
    "\n",
    "# Call function to display misclassified images\n",
    "print(\"\\nVisualizing misclassifications...\")\n",
    "visualize_misclassifications(best_model, test_loader, classes, y_true, y_pred)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5c976950a1620bd6",
   "metadata": {},
   "source": [
    "# Grad-CAM Visualization of Model Decisions\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "80246d342ec1f140",
   "metadata": {},
   "source": [
    "from pytorch_grad_cam import GradCAM, XGradCAM, GradCAMPlusPlus, AblationCAM, EigenCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from pytorch_grad_cam.utils.reshape_transforms import vit_reshape_transform\n",
    "def visualize_gradcam_samples(model, test_loader, classes, y_true, y_pred, num_images=5):\n",
    "    \"\"\"\n",
    "    Use GradCAM to visualize model's attention areas on correctly and incorrectly predicted samples\n",
    "\n",
    "    Args:\n",
    "        model: Trained model\n",
    "        test_loader: Test data loader\n",
    "        classes: List of class names\n",
    "        y_true: List of true labels\n",
    "        y_pred: List of predicted labels\n",
    "        num_images: Number of images to display for each category (correct/incorrect)\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Find indices of misclassified and correctly classified predictions\n",
    "    misclassified_indices = [i for i, (y_t, y_p) in enumerate(zip(y_true, y_pred)) if y_t != y_p]\n",
    "    correctly_classified_indices = [i for i, (y_t, y_p) in enumerate(zip(y_true, y_pred)) if y_t == y_p]\n",
    "\n",
    "    print(f\"Found {len(misclassified_indices)} misclassified and {len(correctly_classified_indices)} correctly classified predictions\")\n",
    "\n",
    "    # Randomly select specified number of samples\n",
    "    if len(misclassified_indices) > num_images:\n",
    "        misclassified_indices = np.random.choice(misclassified_indices, num_images, replace=False)\n",
    "\n",
    "    if len(correctly_classified_indices) > num_images:\n",
    "        correctly_classified_indices = np.random.choice(correctly_classified_indices, num_images, replace=False)\n",
    "\n",
    "    # Create GradCAM object\n",
    "    # For ViT model, typically use layers in the last transformer block\n",
    "    target_layers = [model.blocks[-1].norm1]  # First normalization layer of the last transformer block\n",
    "\n",
    "    # Initialize GradCAM - removed use_cuda parameter\n",
    "    cam = GradCAM(\n",
    "        model=model,\n",
    "        target_layers=target_layers,\n",
    "        reshape_transform=vit_reshape_transform\n",
    "    )\n",
    "\n",
    "    # Collect all images and labels\n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "\n",
    "    print(\"Collecting test data...\")\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            # Add each image in the batch\n",
    "            for i in range(inputs.size(0)):\n",
    "                all_images.append(inputs[i].cpu())\n",
    "                all_labels.append(labels[i].item())\n",
    "\n",
    "    # Set number of rows and columns for images\n",
    "    n_rows = 2  # Misclassified and correctly classified\n",
    "    n_cols = min(num_images, len(misclassified_indices), len(correctly_classified_indices))\n",
    "    \n",
    "    # Each example needs 2 columns: original image and heatmap\n",
    "    plt.figure(figsize=(n_cols * 6, n_rows * 4))\n",
    "\n",
    "    # Visualize misclassified predictions\n",
    "    print(\"Generating GradCAM for misclassified predictions...\")\n",
    "    for i, idx in enumerate(misclassified_indices[:n_cols]):\n",
    "        # Get image and labels\n",
    "        img_tensor = all_images[idx].unsqueeze(0).to(device)\n",
    "        true_label = y_true[idx]\n",
    "        pred_label = y_pred[idx]\n",
    "\n",
    "        # Apply GradCAM\n",
    "        targets = [ClassifierOutputTarget(pred_label)]  # Use predicted class\n",
    "        grayscale_cam = cam(input_tensor=img_tensor, targets=targets)\n",
    "        grayscale_cam = grayscale_cam[0, :]\n",
    "\n",
    "        # Convert image for display\n",
    "        img = img_tensor.cpu().numpy().squeeze().transpose((1, 2, 0))\n",
    "        # Denormalize\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        img = std * img + mean\n",
    "        img = np.clip(img, 0, 1)\n",
    "\n",
    "        # Overlay GradCAM on image\n",
    "        visualization = show_cam_on_image(img, grayscale_cam, use_rgb=True)\n",
    "\n",
    "        # Calculate subplot indices\n",
    "        orig_idx = i * 2 + 1\n",
    "        cam_idx = i * 2 + 2\n",
    "        \n",
    "        # Display original image\n",
    "        plt.subplot(n_rows, n_cols * 2, orig_idx)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Misclassified - Original\\nTrue: {classes[true_label]}\\nPred: {classes[pred_label]}\", color='red', fontsize=9)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Display GradCAM heatmap\n",
    "        plt.subplot(n_rows, n_cols * 2, cam_idx)\n",
    "        plt.imshow(visualization)\n",
    "        plt.title(f\"Misclassified - Heatmap\\nTrue: {classes[true_label]}\\nPred: {classes[pred_label]}\", color='red', fontsize=9)\n",
    "        plt.axis('off')\n",
    "\n",
    "    # Visualize correctly classified predictions\n",
    "    print(\"Generating GradCAM for correctly classified predictions...\")\n",
    "    for i, idx in enumerate(correctly_classified_indices[:n_cols]):\n",
    "        # Get image and labels\n",
    "        img_tensor = all_images[idx].unsqueeze(0).to(device)\n",
    "        true_label = y_true[idx]\n",
    "\n",
    "        # Apply GradCAM\n",
    "        targets = [ClassifierOutputTarget(true_label)]  # Use true class\n",
    "        grayscale_cam = cam(input_tensor=img_tensor, targets=targets)\n",
    "        grayscale_cam = grayscale_cam[0, :]\n",
    "\n",
    "        # Convert image for display\n",
    "        img = img_tensor.cpu().numpy().squeeze().transpose((1, 2, 0))\n",
    "        # Denormalize\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        img = std * img + mean\n",
    "        img = np.clip(img, 0, 1)\n",
    "\n",
    "        # Overlay GradCAM on image\n",
    "        visualization = show_cam_on_image(img, grayscale_cam, use_rgb=True)\n",
    "\n",
    "        # Calculate subplot indices\n",
    "        row_offset = n_cols * 2  # Offset for second row\n",
    "        orig_idx = row_offset + i * 2 + 1\n",
    "        cam_idx = row_offset + i * 2 + 2\n",
    "        \n",
    "        # Display original image\n",
    "        plt.subplot(n_rows, n_cols * 2, orig_idx)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Correctly Classified - Original\\nClass: {classes[true_label]}\", color='green', fontsize=9)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Display GradCAM heatmap\n",
    "        plt.subplot(n_rows, n_cols * 2, cam_idx)\n",
    "        plt.imshow(visualization)\n",
    "        plt.title(f\"Correctly Classified - Heatmap\\nClass: {classes[true_label]}\", color='green', fontsize=9)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('gradcam_visualization.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"GradCAM visualization saved as 'gradcam_visualization.png'\")\n",
    "\n",
    "# Call function\n",
    "print(\"\\nVisualizing model decisions with GradCAM...\")\n",
    "visualize_gradcam_samples(best_model, test_loader, classes, y_true, y_pred, num_images=5)\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
